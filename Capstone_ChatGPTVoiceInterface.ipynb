{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d280519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7fdf1a1f42e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import playsound\n",
    "import time\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request as ur\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from openai import OpenAI\n",
    "from IPython.display import IFrame, HTML\n",
    "from io import BytesIO \n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "\n",
    "key_API=os.environ['OPENAI_API']\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    # or you can explicitly pass in the key (NOT RECOMMENDED)\n",
    "    api_key=key_API,\n",
    ")\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb68e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rl/5sp8_qld00129z3l0nk2jnk00000gp/T/ipykernel_18971/2470282431.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mspeak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Buen día\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m#Translate speech to text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mSpeechText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"es-MX\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mSpeechText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpeechText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/rl/5sp8_qld00129z3l0nk2jnk00000gp/T/ipykernel_18971/2470282431.py\u001b[0m in \u001b[0;36mget_audio\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_for_ambient_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msaid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    489\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mWaitTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"listening timed out while waiting for phrase to start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                     \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# reached end of the stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "## Function which inputs speechtotext using gtts, prefer this from OpenAI due to not costing for the UI\n",
    "def speak(text):\n",
    "    tts = gTTS(text=text, lang=\"es\")\n",
    "    filename = \"voice.mp3\"\n",
    "    tts.save(filename)\n",
    "    playsound.playsound(filename)\n",
    "    \n",
    "#get the audio from the Mic to transform to text so it can interact with the prompts API of OpenAI\n",
    "def get_audio(lang):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source,duration=0.2)\n",
    "        audio = r.listen(source)\n",
    "        said = \"\"\n",
    "\n",
    "        try:\n",
    "            said = r.recognize_google(audio,language=lang)\n",
    "            print(said)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"No logre entenderte, ¿Puedes repetir eso?\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error with the speech recognition service; {e}\")\n",
    "        #return None\n",
    "        except Exception as e:\n",
    "            print(\"Exception: \" + str(e))\n",
    "\n",
    "    return said\n",
    "\n",
    "#Function used to record audio to be used to translate\n",
    "def rec_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source,duration=0.2)\n",
    "        audio = r.listen(source)\n",
    "    said = r.recognize_google(audio,language=\"es-MX\")\n",
    "    print(said)\n",
    "    tts = gTTS(text=said, lang=\"es\")\n",
    "    filename = \"voice.mp3\"\n",
    "    tts.save(filename)\n",
    "    #playsound.playsound(filename)\n",
    "    return filename\n",
    "\n",
    "#Fucntion used to create prompt and interact with dalee    \n",
    "def dalee():\n",
    "    speak(\"Que deseas que ponga en el diseño\")\n",
    "    logo_prompt= \"Tema: \"+get_audio(\"es-MX\")\n",
    "    speak(\"En que estilo\")\n",
    "    logo_prompt=logo_prompt+\" Estilo:\"+get_audio(\"es-MX\") \n",
    "\n",
    "    image_size = 1024\n",
    "    response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=logo_prompt,\n",
    "    size=f\"{image_size}x{image_size}\"\n",
    "    )\n",
    "    image_url = response.model_dump()['data'][0]['url']\n",
    "    url = image_url\n",
    "    with ur.urlopen(url) as url:\n",
    "        img = Image.open(BytesIO(url.read()))\n",
    "    display(img)\n",
    "    print(image_url)\n",
    "    \n",
    "\n",
    "def translate():\n",
    "    speak(\"Reproduce o di lo que deseas traducir\")\n",
    "    audio_file= open(rec_audio(), \"rb\")\n",
    "    translation = client.audio.translations.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file\n",
    "    )\n",
    "    speak(translation.text)\n",
    "    \n",
    "    \n",
    "def assistant():\n",
    "    while True:\n",
    "        speak(\"Como puedo asistirte?\")\n",
    "        #Translate speech to text\n",
    "        SpeechText = get_audio()\n",
    "        SpeechText = SpeechText.lower()\n",
    "        \n",
    "        #Manage if the user wants to leave the \n",
    "        if SpeechText==\"salir\":\n",
    "            speak(\"Ten un buen día\")\n",
    "            break\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Eres un util asistente\"\n",
    "                },\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"{}\".format(SpeechText)\n",
    "                }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Print out results for further processing\n",
    "            print(f\"Human:{SpeechText}\\nAI:{response.model_dump()['choices'][0]['message']['content']}\")\n",
    "\n",
    "            # SPEAK IT OUT\n",
    "            speak(response.model_dump()['choices'][0]['message']['content'])\n",
    "        continue\n",
    "    \n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "\n",
    "        with sr.Microphone() as source:\n",
    "\n",
    "            #Greetings and present options\n",
    "            speak(\"Buen día\")\n",
    "            #Translate speech to text\n",
    "            SpeechText = get_audio(\"es-MX\")\n",
    "            SpeechText = SpeechText.lower()\n",
    "            \n",
    "            #Manage the option the user want to do\n",
    "            if SpeechText==\"salir\":\n",
    "                speak(\"Ten un buen día\")\n",
    "                break\n",
    "            elif \"hello\" in SpeechText:\n",
    "                speak(\"hello, how are you?\")\n",
    "            elif \"what is your name\" in SpeechText:\n",
    "                speak(\"My name is Tim\")\n",
    "            elif \"imagen\" in SpeechText:\n",
    "                dalee()\n",
    "            elif \"asistente\" in SpeechText:\n",
    "                assistant()\n",
    "            elif \"traductor\" in SpeechText:\n",
    "                translate()\n",
    "            \n",
    "                \n",
    "\n",
    "           \n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "       print(\"I didn't quite get you. Can you please repeat that?\")\n",
    "       speak(\"No logre entenderte, ¿Puedes repetir eso?\")\n",
    "       recognizer = sr.Recognizer()\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Error with the speech recognition service; {e}\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception: \" + str(e))\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a2b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
